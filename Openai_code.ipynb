{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd7fded-1d4d-4479-80cb-98683c0fe001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading langchain-0.0.304-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.18)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.11/site-packages (from langchain) (3.7.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
      "  Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.24.4)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, mypy-extensions, marshmallow, jsonpatch, annotated-types, typing-inspect, pydantic, openai, langsmith, dataclasses-json, langchain\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed annotated-types-0.5.0 dataclasses-json-0.6.1 jsonpatch-1.33 langchain-0.0.304 langsmith-0.0.41 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 pydantic-2.4.2 pydantic-core-2.10.1 tenacity-8.2.3 typing-inspect-0.9.0\n",
      "Collecting unstructured==0.5.6\n",
      "  Downloading unstructured-0.5.6.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting argilla (from unstructured==0.5.6)\n",
      "  Downloading argilla-1.16.0-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml (from unstructured==0.5.6)\n",
      "  Downloading lxml-4.9.3-cp311-cp311-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from unstructured==0.5.6)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openpyxl in /opt/conda/lib/python3.11/site-packages (from unstructured==0.5.6) (3.1.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from unstructured==0.5.6) (2.0.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unstructured==0.5.6) (10.0.0)\n",
      "Collecting pypandoc (from unstructured==0.5.6)\n",
      "  Downloading pypandoc-1.11-py3-none-any.whl (20 kB)\n",
      "Collecting python-docx (from unstructured==0.5.6)\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-pptx (from unstructured==0.5.6)\n",
      "  Downloading python_pptx-0.6.22-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-magic (from unstructured==0.5.6)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting markdown (from unstructured==0.5.6)\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from unstructured==0.5.6) (2.31.0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.11/site-packages (from unstructured==0.5.6) (2023.5.7)\n",
      "Collecting httpx<0.24,>=0.15 (from argilla->unstructured==0.5.6)\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla->unstructured==0.5.6)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from argilla->unstructured==0.5.6) (23.1)\n",
      "Collecting pandas (from unstructured==0.5.6)\n",
      "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting pydantic<2.0,>=1.10.7 (from argilla->unstructured==0.5.6)\n",
      "  Downloading pydantic-1.10.13-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.13 (from argilla->unstructured==0.5.6)\n",
      "  Downloading wrapt-1.14.1.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy<1.24.0 (from argilla->unstructured==0.5.6)\n",
      "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.11/site-packages (from argilla->unstructured==0.5.6) (4.65.0)\n",
      "Collecting backoff (from argilla->unstructured==0.5.6)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic (from argilla->unstructured==0.5.6)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting rich!=13.1.0 (from argilla->unstructured==0.5.6)\n",
      "  Downloading rich-13.5.3-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.8.0,>=0.6.0 (from argilla->unstructured==0.5.6)\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.11/site-packages (from pandas->unstructured==0.5.6) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->unstructured==0.5.6) (2023.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured==0.5.6) (8.1.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->unstructured==0.5.6) (1.3.0)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured==0.5.6)\n",
      "  Downloading regex-2023.8.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.4/782.4 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.11/site-packages (from openpyxl->unstructured==0.5.6) (1.1.0)\n",
      "Collecting pillow (from unstructured==0.5.6)\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.5.6)\n",
      "  Downloading XlsxWriter-3.1.5-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->unstructured==0.5.6) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->unstructured==0.5.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->unstructured==0.5.6) (2.0.3)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx<0.24,>=0.15->argilla->unstructured==0.5.6)\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3 (from httpx<0.24,>=0.15->argilla->unstructured==0.5.6)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx<0.24,>=0.15->argilla->unstructured==0.5.6) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<2.0,>=1.10.7->argilla->unstructured==0.5.6) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->unstructured==0.5.6) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich!=13.1.0->argilla->unstructured==0.5.6)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich!=13.1.0->argilla->unstructured==0.5.6) (2.15.1)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured==0.5.6)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured==0.5.6) (3.7.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla->unstructured==0.5.6)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: unstructured, python-docx, wrapt\n",
      "  Building wheel for unstructured (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unstructured: filename=unstructured-0.5.6-py3-none-any.whl size=1315706 sha256=83e49274aec7ccccd3479a0c26a2b3f2dafe4e51702097a79a6edfb0b0bc6f8f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/15/bf/03/c4ad862321479b4b26251ed00484e4b6a1eefbef4ba5512044\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=ce307cf6c9ca531b2cb563cdd6fc28f2900410cab253bee32a39d72617a6859f\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b2/11/b8/209e41af524253c9ba6c2a8b8ecec0f98ecbc28c732512803c\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.14.1-cp311-cp311-linux_x86_64.whl size=39463 sha256=79e444c8d498db90b9c54f45286962b9cd6180adeccb4108c46bcb734116a22b\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/eb/b6/fa/5ab6f4107cad63fa04c54ad78d75bb7035119bdd4f751df5ae\n",
      "Successfully built unstructured python-docx wrapt\n",
      "Installing collected packages: rfc3986, monotonic, XlsxWriter, wrapt, typer, regex, python-magic, pypandoc, pydantic, pillow, numpy, mdurl, markdown, lxml, h11, backoff, python-pptx, python-docx, pandas, nltk, markdown-it-py, httpcore, deprecated, rich, httpx, argilla, unstructured\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.4.2\n",
      "    Uninstalling pydantic-2.4.2:\n",
      "      Successfully uninstalled pydantic-2.4.2\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 10.0.0\n",
      "    Uninstalling Pillow-10.0.0:\n",
      "      Successfully uninstalled Pillow-10.0.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "Successfully installed XlsxWriter-3.1.5 argilla-1.16.0 backoff-2.2.1 deprecated-1.2.14 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 lxml-4.9.3 markdown-3.4.4 markdown-it-py-3.0.0 mdurl-0.1.2 monotonic-1.6 nltk-3.8.1 numpy-1.23.5 pandas-1.5.3 pillow-9.5.0 pydantic-1.10.13 pypandoc-1.11 python-docx-0.8.11 python-magic-0.4.27 python-pptx-0.6.22 regex-2023.8.8 rfc3986-1.5.0 rich-13.5.3 typer-0.7.0 unstructured-0.5.6 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain\n",
    "!pip install unstructured==0.5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d3300a-b672-47c8-8878-1b9583ca3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain/__init__.py:24: UserWarning: Importing OpenAI from langchain root module is no longer supported.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone, Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17344d5f-6766-4d4a-a353-976c331361df",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1c4417-03d0-4595-8fba-df51ce956b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-29 01:27:09--  https://storage.googleapis.com/ds--tasks-datasets/resume-dataset.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.124.207, 172.253.114.207, 172.217.214.207, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.124.207|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 35307 (34K) [application/zip]\n",
      "Saving to: ‘resume-dataset.zip’\n",
      "\n",
      "resume-dataset.zip  100%[===================>]  34.48K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-09-29 01:27:09 (51.0 MB/s) - ‘resume-dataset.zip’ saved [35307/35307]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/ds--tasks-datasets/resume-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9673fd4-2dd6-4551-8ea6-2fa834f7ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  resume-dataset.zip\n",
      "   creating: resume-dataset/\n",
      "  inflating: __MACOSX/._resume-dataset  \n",
      "  inflating: resume-dataset/resume-10  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-10  \n",
      "  inflating: resume-dataset/resume-17  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-17  \n",
      "  inflating: resume-dataset/resume-21  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-21  \n",
      "  inflating: resume-dataset/resume-19  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-19  \n",
      "  inflating: resume-dataset/resume-18  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-18  \n",
      "  inflating: resume-dataset/resume-20  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-20  \n",
      "  inflating: resume-dataset/resume-16  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-16  \n",
      "  inflating: resume-dataset/resume-11  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-11  \n",
      "  inflating: resume-dataset/resume-8  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-8  \n",
      "  inflating: resume-dataset/resume-6  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-6  \n",
      "  inflating: resume-dataset/resume-1  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-1  \n",
      "  inflating: resume-dataset/resume-7  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-7  \n",
      "  inflating: resume-dataset/resume-9  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-9  \n",
      "  inflating: resume-dataset/resume-14  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-14  \n",
      "  inflating: resume-dataset/resume-13  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-13  \n",
      "  inflating: resume-dataset/resume-12  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-12  \n",
      "  inflating: resume-dataset/resume-15  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-15  \n",
      "  inflating: resume-dataset/resume-2  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-2  \n",
      "  inflating: resume-dataset/resume-5  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-5  \n",
      "  inflating: resume-dataset/resume-4  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-4  \n",
      "  inflating: resume-dataset/resume-3  \n",
      "  inflating: __MACOSX/resume-dataset/._resume-3  \n"
     ]
    }
   ],
   "source": [
    "!unzip resume-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936e31d1-8f55-4546-890c-a255eb4a6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_resumes(resume_folder):\n",
    "    # Initialize a dictionary to store parsed resume data with resumeId as the key\n",
    "    parsed_resumes = {}\n",
    "\n",
    "    # Step 1: Iterate through the resume files in the specified directory\n",
    "    for filename in os.listdir(resume_folder):\n",
    "        if filename.startswith(\"resume-\"):\n",
    "            with open(os.path.join(resume_folder, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                resume_content = file.read()\n",
    "\n",
    "            # Extract resumeId from the filename and use it as the key in the dictionary\n",
    "            resume_id = filename.split(\"-\")[1].split(\".\")[0]\n",
    "\n",
    "            # Store the entire resume content in the dictionary\n",
    "            parsed_resumes[resume_id] = resume_content\n",
    "\n",
    "    return parsed_resumes\n",
    "\n",
    "# Example usage of the function\n",
    "resume_folder = \"resume-dataset\"\n",
    "parsed_data = parse_resumes(resume_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def7e7ed-d7a6-43cb-90b2-f210edf9596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ranjeet Kumar\\nTeam Member - Appin Software Group\\n\\nShakarpur, Delhi\\n❖ 2.2 years of IT experience in various technologies like C#.Net, VB.Net, VB 6, VBScript, SQL Server. \\n❖ Experience in development phase of web applications using ASP.NET 3.5. \\n❖ Expertise in implementing .Net technologies with ADO.Net to develop Enterprise applications. \\n❖ Expertise in implementing .Net Design Patterns. \\n❖ Good Knowledge in Web Services and WCF Applications. \\n❖ Good Knowledge in Socket Programming using .Net as well as in VB 6.\\nWork Experience\\nSoftware Developer\\nAppin Software Group - New Delhi, Delhi\\n2011 to Present\\nTeam Size: 5 \\nTechnologies: C#, ADO.Net, SQL Server 2005, Visual Studio 2008, VB 6 \\nApp Server: Windows Application \\n \\nDescription: \\nMatrix Framework is a new tool for Penetration Testing and the ultimate resource to demonstrate the security of your network. With the help of this software, you can easily get the basic information of target by sending mail either in the form of link or attachment by using either Social engineering webpage, Exploits or Payloads. With RAT, you can take the full control of the client machine and you can perform any operation on their machine, you can also use cmd command in CMD shell to perform operation & many more such functionality. \\n \\nResponsibilities: \\n❖ Implemented Action Classes. \\n❖ Implemented Form Design, their coding and tested the entire application. \\n❖ Impose Validations as per the Requirements. \\n❖ Integrated Predefine customized Phishing page, Exploits and Payloads template packs for campaigning. \\n❖ Developed Payloads and Dragon Eye (Socket Programming) using VB 6. \\n❖ Implemented FTP Server Configuration and their Monitoring. \\n❖ Implemented Database using SQL Server as backend and ADO.Net for their connectivity. \\n❖ Fix all the bugs come during running whole Application.\\nSoftware Developer\\nAppin Software Group - New Delhi, Delhi\\nApril 2010 to Present\\nNew Delhi \\n \\nTechnical Skill \\nOperating System Windows-XP, Windows 7 \\nProgramming Languages C, C++, C#, ASP.Net, VB.Net, VB 6.0, VBScript \\nFramework .Net Framework 2.0, 3.5 \\nIntegrated Development Environment Microsoft Visual Studio 2005, 2008 \\nRDBMS MS Access, SQL Server \\nReport Visual Studio Crystal Report \\nTools & Methodologies Software Engineering \\nMarkup Language HTML, XML. \\n \\nPROJECT #1: Matrix Framework \\nPlatform: Windows XP/ 7\\nSoftware Developer\\nAppin Software Group - New Delhi, Delhi\\nApril 2010 to Present\\nTeam Size: 4 \\nTechnologies: C#, Visual Studio 2008, SQL Server 2005 \\nApp Server: ASP.Net \\n \\nDescription: \\naSecure is basically launch for security purpose. This project deals with recognizing the face detection and trace out the face of suspected person, if their information is not matched with the customized database. This will help you to maintain the security in your company by filtering the new faces. \\n. \\n \\nResponsibilities: \\n❖ Responsible for Developing Application Front end using C# \\n❖ Involved in Designing, Coding and Testing of two modules. \\n❖ Developed two modules and Visual Studio Crystal Report. \\n❖ Implemented Database using SQL Server as backend and ADO.Net for their Interaction. \\n❖ Involved in removing bugs. \\n. \\n \\nAchievements, Extra Curricular Activities: \\n➢ Active member of Sports meet at college level. \\n➢ Participation in writing competition in school and college levels.\\nTeam Member\\nAppin Software Group\\nSeptember 2010 to May 2011\\nTeam Size: 4 \\nTechnologies: C#, ADO.Net, Crystal Report, SQL Server 2005, VS 2005. \\nApp Server: Windows Application \\n \\nDescription: \\nCall Data Record Analyzer is used to analysis and tracking criminal on call data record base by most of the intelligence organization of India. This software maintains call data record and make different type of intelligence search to find a important information. This software generate various type of report based on different searches (frequency, time wise, duration wise, call type wise, subscriber, cell id, IMEI based, international call etc) \\n \\nResponsibilities: \\n❖ Analyzed the working scenario and Implemented action classes. \\n❖ Implemented Form Design, their coding and tested three Modules. \\n❖ Impose Validations as per the Requirements. \\n❖ Implemented Database using SQL Server as backend and ADO.Net for their connectivity.  \\nPROJECT #3: aSecure \\nPlatform: Windows XP/ 7\\nEducation\\nB.E in Computer Science\\nGwalior Engineering College Gwalior, Madhya Pradesh\\n2010\\nSkills\\nC,C++,C#,ASP.Net,VB.Net,SQL Server 2005,VB 6,VBScript,Web Services, WCF, Socket Programming,HTML,XML,Javascript.\\nAdditional Information\\nFather’s Name : Mr. Rajkumar Prasad \\nDate of Birth : 21th Dec 1986 \\nMarital Status : Single \\nLanguage Known : English, Hindi \\nNationality : Indian\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data['3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb9dc955-b0ac-47e5-adc6-c3d9f3f4653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResumeSummaryById(resumeid_num):\n",
    "\n",
    "    # Check if the resume_id exists in the dataset\n",
    "    for resume_id, resume_content in parsed_data.items():\n",
    "        # Skip the input resume if its ID matches the target ID\n",
    "        if resume_id == resumeid_num:\n",
    "            continue  # Return None if the resume id is not found\n",
    "\n",
    "    summary_prompt = f\"Please provide a summary of the resume with the following resumeId {resumeid_num}. The response should be in JSON format and include the following keys:\\n\\n```json\\n{{\\n\\\"name\\\": \\\"\\\",\\n\\\"Title/Role\\\": \\\"\\\",\\n\\\"Skills\\\": [],\\n\\\"Technical Skills\\\": [],\\n\\\"experience\\\": \\\"\\\",\\n\\\"background\\\": \\\"\\\"\\n}}\\n```\\n\\nThe data should be extracted from the resume content:\\n\\n```\\n{parsed_data[resumeid_num]}\\n```\\n\\nIf the provided resumeId is not found, please return None.\"\n",
    "\n",
    "    # Define a prompt for summarizing the resume data in JSON format\n",
    "    #prompt = f\"Please provide a summary of the resume with following resumeid{resumeid_num}. The response should be in JSON format include the following keys: name, Title/Role, Skills, Technical Skills, experience, and background extracted from {resume_content}.If the provided resumeId is not found, please return None.\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=summary_prompt,\n",
    "        max_tokens=1000,\n",
    "        n=1,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].text.strip()\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2707480-23de-470e-b7cd-c8d87071fd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n \"name\": \"Puneet Singh\",\\n \"Title/Role\": \"IT Professional\",\\n \"Skills\": [\"Hard Work\", \"Positive Attitude\", \"Self Motivator\", \"Learning From Failure\\'s\", \"Punctual\"],\\n \"Technical Skills\": [\"C\", \"C++\", \".Net\", \"HTML\", \"MS SQL\", \"SQL Server\", \"Microsoft Access\"],\\n \"experience\": \"Fresher\",\\n \"background\": \"Puneet Singh is an IT professional with a Master\\'s degree in Computer Applications and a Bachelor\\'s degree in Computer Applications. He has a strong understanding of C, C++, .Net technology, HTML, and various operating systems. Puneet has experience working on projects such as Online Attendance, Medical Store System, and Online Voting. He has also been described as hardworking, with a positive attitude and a strong self-motivational drive.\"\\n}'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResumeSummaryById('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d7c7ff90-db8d-4850-bfe1-417528c461b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarResume(resumeid_num):\n",
    "\n",
    "    # Define the engine\n",
    "    engine = 'gpt-3.5-turbo-instruct'\n",
    "    # Initialize variables to store the most similar resume and its comparison text\n",
    "    most_similar_resume=[]\n",
    "    Reason=\" \"\n",
    "\n",
    "    for resume_id, resume_content in parsed_data.items():\n",
    "        if resume_id==resumeid_num:\n",
    "            continue\n",
    "\n",
    "        # Define the prompt\n",
    "        similar_resume_prompt = f\"Compare the following resumes:\\n\\n1. {parsed_data[resumeid_num]}\\n\\n2. {resume_content} and determine the most similar one. Provide the reason for this decision by highlighting common skills and their details of {resumeid_num} and the details of most similaresume. Response should be in the following JSON format:\\n\\n{{\\n\\t\\\"isSimilar\\\": bool,\\n\\t\\\"reason\\\": {{}}\\n}}\"\n",
    "\n",
    "        # Generate a comparison result\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=similar_resume_prompt,\n",
    "            max_tokens=350,\n",
    "        )\n",
    "\n",
    "         # Extract the comparison text from the respons\n",
    "        comparison_results = response.choices[0].text.strip()\n",
    "\n",
    "        # Check if this comparison result is more similar than the previous most similar one\n",
    "        if comparison_results:\n",
    "            most_similar_resume=resume_id\n",
    "            Reason=comparison_results\n",
    "\n",
    "    # Determine if the most similar resume is similar enough (you can adjust this threshold)\n",
    "    is_similar=len(Reason)>0\n",
    "    \n",
    "    # Create the JSON response\n",
    "    response_json={\n",
    "        \"isSimilar\":is_similar,\n",
    "        \"mostSimilarResumeId\":most_similar_resume,\n",
    "        \"Reason\":Reason,\n",
    "    }\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f0281f1-e943-427c-88ed-cacdaee9c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'isSimilar': True, 'mostSimilarResumeId': '17', 'Reason': \"The resumes have a few common skills such as HTML, C, and database management. However, Poonam's resume only lists one project while Linda's resume lists two projects, both of which demonstrate proficiency in Java and database management.\\n\\nBased on the similar skills and projects related to Java and database management, it can be concluded that Linda's resume is more similar to the given resume. The reason for this decision is because her resume provides more detailed and relevant information on her experience and skills in these areas, making it a more suitable match than Poonam's resume.\"}\n"
     ]
    }
   ],
   "source": [
    "resume_id = '4'\n",
    "result=getSimilarResume(resume_id)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "befda1c4-e0c8-40de-b6fd-df79db75a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_byskill(input_skills):\n",
    "    # Define the engine \n",
    "    engine = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "    # Initialize variables to store the most similar resumes and their comparison text\n",
    "    most_similar_resumes = []\n",
    "    comparison_texts = []\n",
    "\n",
    "    for resume_id,resume_content in parsed_data.items():\n",
    "        #define the prompt\n",
    "        resume_byskills_prompt = f\"Search for resumes with skills: {', '.join(input_skills)}. Analyze the following resumes for skill matching:\\n{resume_content}. and return 3 most relevent resumes with the skills and the comparison of their {input_skills} skills \"\n",
    "\n",
    "        # Generate a comparison result\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=resume_byskills_prompt,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        # Extract the comparison text from the response\n",
    "        comparison_result = response.choices[0].text.strip()\n",
    "\n",
    "        if comparison_result:\n",
    "            most_similar_resumes.append(resume_id)\n",
    "            comparison_texts.append(comparison_result)\n",
    "\n",
    "            # Keep only the top 3 most similar resumes\n",
    "            if len(most_similar_resumes) > 2:\n",
    "                most_similar_resumes = most_similar_resumes[:3]\n",
    "                comparison_texts = comparison_texts[:3]\n",
    "\n",
    "    #check if any similar resume found \n",
    "    are_similar=len(most_similar_resumes)>0\n",
    "    \n",
    "    # Create the JSON response\n",
    "    response_json = {\n",
    "        \"areSimilar\": are_similar,\n",
    "        \"mostSimilarResumeIds\": most_similar_resumes,\n",
    "        \"comparisonTexts\": comparison_texts,\n",
    "    }\n",
    "\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d8841af-1d77-41d6-9d16-2c805e046735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'areSimilar': True, 'mostSimilarResumeIds': ['13', '18', '2'], 'comparisonTexts': [\"Resume 1:\\nSanthoshkumar V - Relevant skills: ['Software developer', 'Asp.Net', 'VB.net', 'Crystal reports', 'HTML', 'CSS', 'JavaScript', 'MySQL server', 'Web service']\\nSoftware developer experience: 1 year\\nJava Developer experience: None\\nAdditional relevant skills: Designing in Adobe Photoshop, Corel Draw, knowledge in software & hardware servicing & installation\\n\\nResume 2:\\nNo relevant skills found for Java Developer. \\n\\nResume 3:\\nNo relevant skills found for Java Developer.\", \"1. Divya Sr. Java Developer - Strong skill match for both 'Software developer' and 'Java Developer'\\n2. Sr. Java Developer - Strong skill match for 'Java Developer' and some skills for 'Software developer'\\n3. Sudhir Java Developer - Strong skill match for 'Java Developer' and some skills for 'Software developer'.\", '1. Shivani Dubey\\nPune, Maharashtra\\n• Extensive experience in Java programming language, with expertise in web development using Java \\n• Hands-on experience in working with various frameworks like Spring, Hibernate \\n• Proficient in technologies like HTML, CSS, JavaScript, jQuery, and AJAX \\n• Strong understanding of OOP concepts and design patterns \\n• Experience in working with databases such as MySQL and Oracle \\n• Proven track record in delivering high-quality software products within tight deadlines \\n• Excellent problem-solving and analytical skills \\n\\n2. Harsh Sharma\\nMumbai, Maharashtra\\n• Over 4 years of experience in software development with expertise in Java programming \\n• Proficient in frameworks like Spring Boot, Spring MVC, and Hibernate \\n• Strong understanding of SQL and relational databases \\n• Skilled in using JavaScript, HTML, and CSS for web development \\n• Experience in working with agile methodologies \\n• Excellent communication and teamwork skills \\n• Knowledge of design patterns and software architecture principles \\n\\n3. Rahul Gupta\\nGurgaon, Haryana\\n• 6 years of experience as a software developer with specialization in Java development \\n• Proficient in using Java frameworks such as Struts, Spring, and Hibernate \\n• Skilled in web development using HTML, CSS, JavaScript, and jQuery \\n• Experience in working with databases like MySQL, Oracle, and MongoDB \\n• Good understanding of OOP concepts and design patterns \\n• Familiar with agile development practices \\n• Strong problem-solving and analytical skills \\n\\nComparison:\\n\\n1. Shivani Dubey has relevant experience in Java development and hands-on experience in working with frameworks like Spring and Hibernate, making her a suitable candidate for the role of a Java Developer.\\n\\n2. Harsh Sharma has experience in Java development as well as strong skills in using frameworks and technologies such as Spring Boot, Hibernate, and JavaScript. He also has experience in working with agile methodologies, making him a suitable candidate for a Software Developer position.\\n\\n3. Rahul Gupta has extensive experience in Java development and proficiency in using frameworks like Struts and Spring. He also has experience in web development using HTML, CSS, and JavaScript, making him a potential candidate for both Software Developer and Java Developer roles.']}\n"
     ]
    }
   ],
   "source": [
    "# Target skills to search for\n",
    "target_skills = [\"Software developer\",\"Java Developer\"]\n",
    "\n",
    "# Call the function with target_skills and parsed_data\n",
    "result = get_resume_byskill(target_skills)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed17a5-7a43-47eb-9f75-4424ab1b2781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
